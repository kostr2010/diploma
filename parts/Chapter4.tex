\section{Результаты проделанной работы}
\label{sec:Chapter4} \index{Chapter4}

В этом разделе будут приведены детали реализации классификатора, схема его работы и будут обсуждены возникшие в процессе реализации проблемы.

\subsection{Структура проекта}

Весь проект был реализован на языке python3 с использованием библиотек sklearn и XGBoost, из которых были взяты модели решающего дерева и градиентного бустинга соответственно. Структурно, проект можно разбить на три модуля:

\begin{enumerate}
    \item Модуль, генерирующий датасет из Juliet Test Suite. Принцип его работы был описан в разделе \ref{sec:dataset}.
    \item Модуль, извлекающий признаки из указанного файла, чтобы можно было приоритизировать уязвимости, найденные в нем анализатором. Этот модуль работает аналогично предыдущему, с единственным отличием в том, что он не размечает полученные данные.
    \item Классификатор, определяющий принадлежность сообщения анализатора к true positive или false positive. Этот модуль принимает на вход датасет составленный первым модулем и список объектов от второго, после чего обучает две модели на тренировочной выборке и дает предсказания для полученных объектов.
\end{enumerate}

С полным исходным кодом можно ознакомиться по сслыке \cite{source-code}.

\subsection{Пример работы}

Пусть есть исходный файл input.c, который нам необходимо проанализировать. Первым делом необходимо передать этот файл на вход второму модулю, в результате чего получим примерно следующий вывод:

\begin{verbatim}
    // data.csv
    401,0.0,0.0,0.0,0.0,0.0,5.0,21.0,22.0,5.0,21.0,93.0, ...
    775,22.0,5.0,5.0,21.0,13.0,13.0,22.0,91.0,21.0,5.0, ... 
    415,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0, ...
\end{verbatim}

Как было обусловлено в разделе \ref{sec:dataset}, первый столбец этой таблицы - это CWE код найденной анализатором ошибки. Далее идет окно токенов, после которого идут метрики кода. Нули в окне токенов означают выход за границы функции, в которой обнаружена ошибка.

Следующим шагом будет подать полученный data.csv на вход третьему модулю. После того, как обе модели обучатся на тренировочной выборке, будет выведен результат предсказания: метки и распределения классов в каждом из листьев. Ниже приведено предсказание для полученных выше объектов:

\begin{verbatim}
    predict tree
    [1 0 0] // решающее дерево предсказало, что CWE401 - true 
            // positive, а CWE775 и CWE415 - false positive 
    [[0.00204499 0.99795501]  // Здесь приведены распределения по
     [1.         0.        ]  // классам для каждого из узлов
     [1.         0.        ]]  
    predict xgboost
    [1 0 1] // предсказание модели градиентный бустинг отличается от
            // предыдущего тем, что CWE415 - тоже true positive
    [[0.0170452  0.9829548 ]  // Уверенность ниже, но зато больше 
     [0.9532441  0.0467559 ]  // обобщающая способность
     [0.03121328 0.9687867 ]]
\end{verbatim}

Как видно из листинга выше, предсказания двух моделей расходятся, и только модель на основе градиентного бустинга корректно классифицировала все ошибки. Как видно из распределения классов, решающее дерево на $100\%$ уверено в своем неверном вердикте, что говорит о том, что модель скорее всего была переобучена. Модель на основе градиентного бустинга же наоборот, хоть и менее уверена в своем ответе, но верно классифицировала все три случая, что говорит о ее хорошей обобщающей способности. Также этот успех говорит о том что распознавание шаблонов false positive работает с достаточно хорошей общностью, т.к. структура у типичного теста Juliet Test Suite и input.c немного, но различалась.

\subsection{Полученные результаты, их анализ}

Главной проблемой полученного классификатора является ограниченность обучающей выборки. В ней на примерно 3000 объектов приходится примерно 400 объектов класса false positive, то есть очень велика склонность к переобучению (как мы видели на примере решающего дерева выше) или неспособности вывести какой либо шаблон из тренировочных данных. Такое малое количество false positive объясняется качеством анализаторов и малым разнообразием кодовой базы тестовой сюиты. Другими словами, на таких простых примерах современные статические анализаторы выдают малое количество false positive, а однообразие тестов обеспечивает то, что если false positive и обнаружится, то он будет только одного шаблона. Возможным решением данной проблемы является внедрение кодовых баз из других тестовых сюит, а также внедрение спекулятивных методов разметки датасета. Однако это уже является предметом дальнейших исследований.

Для каждой из моделей были замерены две величины: precision и recall. Определим их:

\begin{enumerate}
    \item precision - отношение true positive решений классификатора к сумме true positive и false positive предсказаний классификатора. В нашем случае false positive классификатора - это пометка верного сообщения статического анализатора как false positive. Этот сценарий крайне нежелателен, т.к. сводит к нулю смысл всей работы (если все равно придется перепроверять все сообщения, помеченные классификатором как false positive, то цель по сокращению затрачиваемого времени не может считаться достигнутой). Таким образом, нам крайне важно, чтобы precision стремился к 1.
    \item recall - отношение true positive решений классификатора к сумме true positive и false negative предсказаний классификатора. В нашем случае это доля тех false positives, которые мы не упустили. Хоть в идеале и эта величина должна стремиться к 1, однако ее отклонение от 1 не так критично.
\end{enumerate}

Ниже приведены средние значения precision и recall для обеих моделей:

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        модель              & precision & recall \\ \hline
        решающее дерево     & 0.95      & 0.88   \\ \hline
        градиентный бустинг & 0.98      & 0.94   \\ \hline
    \end{tabular}
    \caption{Результаты классификатора для обеих моделей на тестовой выборке}
\end{table}

Как видно из результатов, градиентный бустинг лучше справляется с задачей классификации и обладает большей обобщающей способностью на тестовой выборке.

Для того, чтобы проверить предположение о целесообразности добавления token-based представления в качестве признаков, было произведено повторное обучение на частичном датасете, не включающем окно токенов. Были получены следующие результаты:
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        модель              & precision & recall \\ \hline
        решающее дерево     & 0.89      & 0.43   \\ \hline
        градиентный бустинг & 0.90      & 0.46   \\ \hline
    \end{tabular}
    \caption{Результаты классификатора для обеих моделей на тестовой выборке без окна токенов}
\end{table}

Как видно из таблицы, точность определения false positive без использования токенов является очень малой. Далее приведем предсказания обученных на таком датасете моделей для уже известного файла input.c, правильные предсказания для которого известны:

\begin{verbatim}
    predict tree
    [0 0 1]
    [[0.96153846 0.03846154]
     [0.96153846 0.03846154]
     [0.01092896 0.98907104]]
    predict xgboost
    [1 0 0]
    [[0.1660918  0.8339082 ]
     [0.793877   0.20612301]
     [0.64596635 0.35403365]]
\end{verbatim}

Как видно из листинга, ни одна из моделей не смогла дать адекватного предсказания на реальных данных. Таким образом, предположение о том, что отфильтрованное token-based представление улучшает способность моделей к распознаванию шаблонов, оказалось верным. К схожим выводам можно было прийти из анализа деревьев, полученных в результате обучения.

Поговорим более подробно об анализе деревьев и о том, какую информацию он может дать. В первую очередь, анализ подобных деревьев может быть полезен для разработчиков статических анализаторов в процессе настройки или отладки. В процессе настройки разработчиком статического анализатора, у него имеется большая база данных со статистикой использования анализатора, по которой он смотрит на аномальные поведения и настраивает нужные метрики соответствующим образом. Вручную этот процесс занимает очень долгое время, однако при помощи анализа подобных деревьев может быть ускорен. Поскольку в узлах деревьев содержатся только метрики, которые наиболее существенны при классификации, на их настройку стоит обращать внимание в первую очередь. На кодовой базе Juliet Test Suite такими метриками наряду с token-based представлением были:

\begin{enumerate}
    \item CWE код ошибки.
    \item Количество операторов доступа к элементу массива.
    \item Цикломатичческая сложность функции.
    \item Количество приведений типов.
    \item Количество ключевых слов else.
    \item Вложенность функции.
    \item Количество прямых доступов к членам структур.
\end{enumerate}

Таким образом, методы, описанные в данной работе, могут быть применены на практике как пользователями статических анализаторов, так и их разработчиками.

\newpage