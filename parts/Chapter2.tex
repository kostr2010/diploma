\chapter{Обзор существующих решений и литературы}
\label{sec:Chapter2} \index{Chapter2}

Необходимость поддержки множества анализаторов обуславливается еще и тем, что каждый анализатор покрывает лишь конечное число уязвимостей, упуская остальные\cite{Delaitre2013OfMS, 3291, Bessey2010AFB}. Поэтому для получения наиболее полного по типам ошибок датасета необходимо уметь обрабатывать сообщения от разных анализаторов. Решением данной проблемы является приведение всех кодов ошибок к кодам CWE \cite{CWE-doc} на этапе обработки сообщения и использование соответствующего кода CWE в датасете при обучении и классификации. Таким образом, добавление поддержки нового анализатора заключается в трансляции кода ошибок анализатора в CWE. Более подробно данный метод будет описан в дальнейшем в соответствующем разделе \ref{sec:Err-to-CWE}.

Sarah Heckman и Laurie Williams в своем исследовании\cite{HECKMAN2011363} выделили следующие признаки, используемые в наиболее релевантных работах о классификаторах, подобных тому, который является целью данного диплома:
\begin{enumerate}
    \item Характеристики ошибки - атрибуты предупреждения, сгенерированного статистиким анализатором, например: тип ошибки (double free, etc.), местоположение в коде (файл, класс, функция, строка, etc.), а также приоритет, который анализатор присвоил ошибке.
    \item Характеристики кода - метрики кода, в котором содержится предупреждение. Эти метрики могут быть извлечены при помощи дополнительного анализа или из самого кода (цикломатическая сложность, количество строк в файле, etc.).
    \item Метрики репозитория с исходным кодом - атрибуты репозитория с исходным кодом (история коммитов, частота изменения кода, история ревью, etc.)
    \item Метрики базы данных с багами - информация о багах может быть связана с изменениями в исходном коде для того, чтобы идентифицировать уязвимость и необходимые исправления.
    \item Метрики динамического анализа - гибридное использование статического и динамического анализа может помочь устранить затраты, связанные с исполнением каждой техники анализа.
\end{enumerate}

В данной работе внимание было сосредоточено целиком на первых двух пунктах: характеристики ошибки и характеристики кода. Изучив соответствующие статьи, было выяснено, что основными характеристиками кода для последующего анализа являются метрики, такие как число вложенности функции, число условных переходов, цикломатическая сложность, etc \cite{test-suites-for-dataset}. Однако все эти метрики являются метаданными, которые лишь характеризуют код в целом, не давая понятия о его структуре. Для того, чтобы каким либо образом анализировать структуру кода обычно используется представление AST\cite{Shedko2020ApplyingPM}. Такой подход хорош для таких языков как Java, Python, где AST может быть легко получено. Для получения же AST в C/C++ необходима полная компиляция проекта. Т.к. каждый проект имеет свои систему для сборки, то невозможно описать данную процедуру единым простым путем. Поэтому в данной работе был опробован подход на основе token-based представления кода, предложенного в \cite{Shedko2020ApplyingPM} для задач определения стиля проекта и вывода правил использования API. Идея состоит в том, что хоть представление в виде токенов и является неточным, но отфильтровав его, и анализируя наряду с метаданными кода, может быть получена более полная картина, нежели чем при использовании только метаданных. Включение токенов в обучающую выборку производилось в предположении, что все false positives следуют определенным шаблонам, которые могут быть определены при помощи предварительно обработанного token-based представления кода. Данное предположение было подробно изучено в работе Zachary P. Reynolds\cite{Reynolds}, в которой была произведена классификация этих шаблонов для нескольких статических анализаторов. Более подробно о token-based представлении в качестве признаков будет рассказано в соответствующем разделе \ref{sec:Tokens}.

В большинстве рассмотренных работ для классификации используются либо решающие деревья, либо LSTM нейронные сети\cite{test-suites-for-dataset, assesing-validity-of-sa-warnings-cisco}. В данной работе будет рассмотрен только классификатор на основе решающих деревьев, и решения на основе рекуррентных нейронных сетей являются предметом дальнейших исследований, т.к. могут помочь находить более сложные шаблоны ошибок.

Для разметки датасета предлагаются разные способы. Anshul Tanwar с коллегами в своей работе \cite{assesing-validity-of-sa-warnings-cisco} предлагают способ разметки false positive на основе истории коммитов репозитория. В своей статье авторы брали исправления разработчиков в течение жизни проекта и сопоставляли их с отчетами статического анализатора. После чего производилась разметка: если исправление касалось куска кода, в котором анализатор находил уязвимость, то ставилась метка true positive, тоесть верное предсказание. Иначе, если разраобтчик помечал данный кусок кода как безопасный, то сообщение анализатора помечалось как false positive. Этот подход обладаем многими преимуществами, такими как больший охват различных сценариев срабатывания анализатора, тоесть обученный на подобных данных классификатор будет более гибким, т.к. запомнит более реалистичные шаблоны, нежели классификатор, обученный на рукописных тестах. Также преимуществом данного подхода является относительная простота реализации. Минусами же данного подхода являются три вещи. Первая - это необходимость наличия сторого формализованной истории коммитов в репозитории, чтобы суметь эффективно извлечь информацию об исправлениях. Вторая - необходимость наличия сообщений, помеченных разработчиками как false positive, что возможно только при должном уровне интеграции статического анализа в процесс разработки, что, как показал предыдущий анализ литературы, является большой редкостью. Третья же вещь - необходимость запускать анализ проекта много раз на разных этапах жизни для корректной разметки, что является очень ресурсоемким и долгим процессом. Другой подход, предложенный в работе Lori Flynn с коллегами \cite{test-suites-for-dataset}, избегает многих минусов первого подхода за счет уменьшения охвата кодовой базы. В этой статье авторы использовали Juliet Test Suite - набор рукописных тестов, предназначенных для валидации эффективности различных статистиких анализаторов\cite{Juliet} для составления и разметки своего датасета. Подход к генерации датасета, используемый в данной работе был позаимствован из этой работы.

\newpage